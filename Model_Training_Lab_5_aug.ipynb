{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshat13shah/data_augmentation_and_modeltraining/blob/main/Model_Training_Lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ANP4KzHPM7"
      },
      "source": [
        "## CS203 Lab Assignment 5\n",
        "\n",
        "### Team Number: 18\n",
        "* Name: Paras Prashant Shirvale\n",
        "* Roll No: 23110232\n",
        "---\n",
        "* Name: Akshat Shah\n",
        "* Roll No: 23110293\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZN86VFHPsZ"
      },
      "source": [
        "### Task 2: Model Training\n",
        "*Note: Initial weights of the model should be the same when training with both datasets.*\n",
        "\n",
        "1. Choose (microsoft/resnet-50)model from the hugging face and initialize its new weights.\n",
        "2. Train model(created in the above point) on a downloaded dataset, without augmentation.\n",
        "3. Train model(created in the first point) on a downloaded dataset with augmentation.\n",
        "4. Get the precision, recall, F1 score, and accuracy of both the models on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SsQd-pA9IGjs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2025.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "from transformers import AutoImageProcessor, ResNetConfig, ResNetForImageClassification\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms, datasets\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1HOHeSMeIoLg"
      },
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "aug_path = \"/teamspace/studios/this_studio/data_augmentation_and_modeltraining/Augmented_Images\"\n",
        "og_path = \"/teamspace/studios/this_studio/data_augmentation_and_modeltraining/test\"\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet expects 224x224 input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard ResNet normalization\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "224 140\n"
          ]
        }
      ],
      "source": [
        "aug_dataset = datasets.ImageFolder(root=aug_path, transform=transform)\n",
        "og_dataset = datasets.ImageFolder(root=og_path, transform=transform)\n",
        "print(len(aug_dataset),len(og_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuWd_xWDI2J5",
        "outputId": "b93faf0c-3212-4b38-c22d-afed802b8be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "336 28\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "random.seed(42)\n",
        "n = len(og_dataset)\n",
        "cats = og_dataset.imgs[:n//2]\n",
        "dogs = og_dataset.imgs[n//2:]\n",
        "\n",
        "og_train = cats[:56] + dogs[:56]\n",
        "full_test = cats[56:] + dogs[56:]\n",
        "full_train = aug_dataset.imgs + og_train\n",
        "\n",
        "print(len(full_train), len(full_test))\n",
        "random.shuffle(full_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zTUylapGhEA",
        "outputId": "90722619-ede6-4bdb-d3b7-6a5c7f384d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([16, 3, 224, 224]) torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_list, transform=None):\n",
        "        self.img_list = img_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.img_list[idx]\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Assuming 'train' and 'test' lists are already created and shuffled\n",
        "train_dataset = CustomDataset(full_train, transform=transform)\n",
        "test_dataset = CustomDataset(full_test, transform=transform)\n",
        "\n",
        "# Create DataLoader for train and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Example of using the DataLoader\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jvh26NHQHsTY"
      },
      "outputs": [],
      "source": [
        "image1, lbl1 = train_dataset[0]\n",
        "image2, lbl2 = train_dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxzKD92YIBft",
        "outputId": "a58afc1d-383d-49f5-a67b-f70df6c10270"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lbl1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = og_dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5SqVm1KgAFP",
        "outputId": "c45129b9-8f45-4483-bdae-af766ccfd1e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQh0JLnVfxAy",
        "outputId": "6eee1c1b-44a9-4375-9401-2fc15f682b45"
      },
      "outputs": [],
      "source": [
        "# Load the model configuration and set it up with random weights initialization\n",
        "config = ResNetConfig.from_pretrained(\"microsoft/resnet-50\")\n",
        "config.num_labels = len(classes)\n",
        "\n",
        "# Initialize the model with the custom configuration (without pretrained weights)\n",
        "model = ResNetForImageClassification(config)\n",
        "\n",
        "# Initialize weights randomly using a custom function if needed\n",
        "def init_weights(module):\n",
        "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(module.weight)\n",
        "        if module.bias is not None:\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "\n",
        "#model.apply(init_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfrRiNqzgkx9",
        "outputId": "f54671a6-aae8-4de5-930a-76f81a25bf53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNetConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"ResNetForImageClassification\"\n",
              "  ],\n",
              "  \"depths\": [\n",
              "    3,\n",
              "    4,\n",
              "    6,\n",
              "    3\n",
              "  ],\n",
              "  \"downsample_in_bottleneck\": false,\n",
              "  \"downsample_in_first_stage\": false,\n",
              "  \"embedding_size\": 64,\n",
              "  \"hidden_act\": \"relu\",\n",
              "  \"hidden_sizes\": [\n",
              "    256,\n",
              "    512,\n",
              "    1024,\n",
              "    2048\n",
              "  ],\n",
              "  \"layer_type\": \"bottleneck\",\n",
              "  \"model_type\": \"resnet\",\n",
              "  \"num_channels\": 3,\n",
              "  \"out_features\": [\n",
              "    \"stage4\"\n",
              "  ],\n",
              "  \"out_indices\": [\n",
              "    4\n",
              "  ],\n",
              "  \"stage_names\": [\n",
              "    \"stem\",\n",
              "    \"stage1\",\n",
              "    \"stage2\",\n",
              "    \"stage3\",\n",
              "    \"stage4\"\n",
              "  ],\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.48.3\"\n",
              "}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uqEn7C8qHr6",
        "outputId": "661bc785-9bb7-4fa2-a76e-0a5654ecd8bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (4): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (5): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UxlWKNGK0P9F"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def evaluate_model(test_loader, model, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy}%\")\n",
        "\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(train_loader, model, device, num_epochs=5):\n",
        "    model.to(device)  # Move the model to the device (GPU or CPU)\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Use Adam optimizer\n",
        "    criterion = torch.nn.CrossEntropyLoss()  # Use CrossEntropy loss for classification\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move both inputs and labels to the device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs).logits  # Forward pass through the model\n",
        "            loss = criterion(outputs, labels)  # Calculate loss\n",
        "            loss.backward()  # Backpropagation\n",
        "\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            running_loss += loss.item()  # Track the loss\n",
        "\n",
        "        # Print the loss for this epoch\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "        evaluate_model(test_loader, model, device)\n",
        "\n",
        "\n",
        "\n",
        "# # Function to evaluate the model on the test set\n",
        "# def evaluate_model(test_loader, model, device):\n",
        "#     model.to(device)\n",
        "#     model.eval()\n",
        "\n",
        "#     all_preds = []\n",
        "#     all_labels = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in test_loader:\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs).logits\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "\n",
        "#             all_preds.extend(preds.cpu().numpy())\n",
        "#             all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "#     # Calculate precision, recall, F1 score, and accuracy\n",
        "#     precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "#     accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "#     return precision, recall, f1, accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH9auBGfpreA",
        "outputId": "5d77cb81-d0b0-4315-8e9f-1a4332dec82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 0.722486062483354\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 2/50, Loss: 0.7375274896621704\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 3/50, Loss: 0.7630111900242892\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 4/50, Loss: 0.7104673385620117\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 5/50, Loss: 0.6595728343183344\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 6/50, Loss: 0.6156281991438433\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 7/50, Loss: 0.6103344884785739\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 8/50, Loss: 0.5905933298847892\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 9/50, Loss: 0.5060427324338392\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 10/50, Loss: 0.5193629400296644\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 11/50, Loss: 0.5527083575725555\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 12/50, Loss: 0.5354589521884918\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 13/50, Loss: 0.45512094551866705\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 14/50, Loss: 0.5084196776151657\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 15/50, Loss: 0.434357225894928\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 16/50, Loss: 0.3955772708762776\n",
            "Test Accuracy: 53.57142857142857%\n",
            "Epoch 17/50, Loss: 0.48438420078971167\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 18/50, Loss: 0.44474642385136\n",
            "Test Accuracy: 57.142857142857146%\n",
            "Epoch 19/50, Loss: 0.33355136893012305\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 20/50, Loss: 0.23148652640256015\n",
            "Test Accuracy: 53.57142857142857%\n",
            "Epoch 21/50, Loss: 0.22880217162045566\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 22/50, Loss: 0.2411855005405166\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 23/50, Loss: 0.36471694911068137\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 24/50, Loss: 0.33804455399513245\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 25/50, Loss: 0.3521139459176497\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 26/50, Loss: 0.29344561425122345\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 27/50, Loss: 0.2320137470960617\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 28/50, Loss: 0.21677319570021195\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 29/50, Loss: 0.1651107377626679\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 30/50, Loss: 0.16805998574603687\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 31/50, Loss: 0.17839507419954648\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 32/50, Loss: 0.1661988618698987\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 33/50, Loss: 0.17099541154774753\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 34/50, Loss: 0.09733850915323604\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 35/50, Loss: 0.1269294854930856\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 36/50, Loss: 0.15765452147884804\n",
            "Test Accuracy: 50.0%\n",
            "Epoch 37/50, Loss: 0.142821536145427\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 38/50, Loss: 0.18638649041002447\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 39/50, Loss: 0.11870364760133353\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 40/50, Loss: 0.09758393678136847\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 41/50, Loss: 0.11683605996553194\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 42/50, Loss: 0.09970410066572102\n",
            "Test Accuracy: 42.857142857142854%\n",
            "Epoch 43/50, Loss: 0.055559087375348266\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 44/50, Loss: 0.06216198032383214\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 45/50, Loss: 0.08574391969225624\n",
            "Test Accuracy: 28.571428571428573%\n",
            "Epoch 46/50, Loss: 0.056476259688762104\n",
            "Test Accuracy: 39.285714285714285%\n",
            "Epoch 47/50, Loss: 0.08064525574445724\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Epoch 48/50, Loss: 0.062131105329502716\n",
            "Test Accuracy: 57.142857142857146%\n",
            "Epoch 49/50, Loss: 0.03644312401725487\n",
            "Test Accuracy: 35.714285714285715%\n",
            "Epoch 50/50, Loss: 0.054707669229670006\n",
            "Test Accuracy: 46.42857142857143%\n",
            "Test Accuracy: 46.42857142857143%\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Train the model\n",
        "train_model(train_loader, model, device, num_epochs=50)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluate_model(test_loader, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw5GGf7kVJMr",
        "outputId": "7e56e6aa-a6e5-4eca-cb36-89c26c3297fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.80952380952381%\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(train_loader, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr9JLVZT0SyS"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA is available and select the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train and evaluate on the dataset without augmentation\n",
        "print(\"Training without augmentation:\")\n",
        "train_model(train_dataloader, model, device, num_epochs=5)\n",
        "precision, recall, f1, accuracy = evaluate_model(test_dataloader, model, device)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Accuracy: {accuracy}\")\n",
        "\n",
        "# # Reinitialize the model (same random weights) for training with augmentation\n",
        "# model.apply(init_weights)  # Reinitialize to maintain same random weights\n",
        "\n",
        "# # Train and evaluate on the dataset with augmentation\n",
        "# print(\"Training with augmentation:\")\n",
        "# train_model(train_loader_with_augmentation, model, device, num_epochs=5)\n",
        "# precision, recall, f1, accuracy = evaluate_model(test_loader, model, device)\n",
        "# print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nu5v1FRhfEG"
      },
      "outputs": [],
      "source": [
        "def init_weights(module):\n",
        "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(module.weight)\n",
        "        if module.bias is not None:\n",
        "            torch.nn.init.zeros_(module.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93tzHnpuST0d"
      },
      "outputs": [],
      "source": [
        "# # Step 1: Set a fixed random seed for reproducibility\n",
        "# seed = 42\n",
        "# torch.manual_seed(seed)  # For PyTorch\n",
        "# np.random.seed(seed)     # For NumPy\n",
        "# torch.cuda.manual_seed(seed)  # If using GPU\n",
        "# torch.cuda.manual_seed_all(seed)  # If using multiple GPUs\n",
        "# torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
        "# torch.backends.cudnn.benchmark = False   # Disable cudnn auto-tuner for consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv381rQFgU2l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LJd9AsRSbt6"
      },
      "outputs": [],
      "source": [
        "# Step 2: Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12Cc8WLeScTY"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load ResNet-50 from Hugging Face\n",
        "model_name = \"microsoft/resnet-50\"\n",
        "model = ResNetForImageClassification.from_pretrained(model_name)\n",
        "config = model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QdZpRqFDSfA4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Initialize the model's weights with new random weights\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2F1qKpRLTmWN"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8neMCp_TvFw"
      },
      "outputs": [],
      "source": [
        "# Image for the Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_STadmpXQw3"
      },
      "outputs": [],
      "source": [
        "# Step 6: Dataset paths and Image preprocessing (No Augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL-lStSkcpwi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd8JIvWCc6MJ"
      },
      "outputs": [],
      "source": [
        "# Step 7: Set up the training loop\n",
        "def train_model(train_loader, model, device, num_epochs=5):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = model(inputs).logits  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Optimize the model parameters\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmOrag4cdUIb"
      },
      "outputs": [],
      "source": [
        "# Step 8: Train the model\n",
        "train_model(train_loader, model, device, num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb-0Swv1dVdQ"
      },
      "outputs": [],
      "source": [
        "# Step 9: Evaluate the model on the test set (optional)\n",
        "def evaluate_model(test_loader, model, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMIKpPiiq0qOKfy1AkZu0dF",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "https://github.com/Akshat13shah/data_augmentation_and_modeltraining/blob/main/Model_Training_Lab_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
